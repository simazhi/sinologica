<!DOCTYPE html>
<html>
  <head>
    <title>Prototypes and the basic level</title>
    <meta charset="utf-8">
    <meta name="author" content="Thomas Van Hoey" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Prototypes and the basic level
### Thomas Van Hoey
### 2018/04/17

---




class: center

# Let's look back at Taylor (2008:48-49)



![](images/semas_onomas.png)

.pull-left[
**semasiological**

what does a word MEAN?

Rosch

prototype

horizontal
]

.pull-right[
**onomasiological**

what is a meaning CALLED?

Berlin &amp; Kay

color, taxonomy: basic level

vertical
]

---
class: center, middle

# Geeraerts's research on onomasiology

![](images/group.jpg)


---
class: center

# Basic level of clothing 

![](images/basiclevelberlin.png)
--
.left[Based on Geeraerts (2010:199-203):

&gt;If we apply the basic-level model to the lexical field of **clothing terminology**, items like ***trousers, skirt, sweater, dress*** are to be considered basic level categories: 
* their overall frequency in actual language use is high, 
* they are learnt early in acquisition,
* they typically have the monomorphemic form of basic level categories.

]
---

# "Obsession with women's clothing"

`Geeraerts, Grondelaers &amp; Bakema (1994)`:  
*The structure of lexical variation: Meaning, naming, and context* 

.pull-left[
**material**

* clothing magazines
* 'window shopping'
* both in Belgium and Netherlands
]

.pull-right[
**methodology**

collecting the *referents* and the *names* in order to get at entrenchment statistics
]

---
class: center, middle

# Cross-classification

![](images/crossnaming.png)

How to classify `wikkelrok` vs. `legging`?  
It depends on the superordinate category that is chosen.

---

# Miniconclusion

As `Atran (1990)` argues, the basic-level model does not apply to artefacts, because artefacts, in contrast with natural kinds, can be linked to various superordinate categories.

Just like prototype theory, there might be some `fuzziness` and `differences of structural weight` involved in taxonomies.

---

# Taylor (2008): 6.3 Constructions

&gt;Constructions: "patterns for the combination of smaller linguistic units, such as words, morphemes, and phrases."

They can be described from
* semantic perspective: what is the meaning conveyed by the construction?
* formal perspective: (what kinds of items are likely to occur in the construction, and in what kind of configuration?

---

# Verhagen's (2005) Wh-extractions

Based on the small, 720,000 word Eindhoven corpus, Verhagen found that `denken` 'think' was the most frequent verb in a long-distance Wh-extraction (one of the big issues of Generative Grammarians).

&lt;table border="0"&gt;
&lt;tr&gt; 
 &lt;td  align="left"&gt;En&lt;/td&gt;
 &lt;td  align="left"&gt;wat&lt;/td&gt;
 &lt;td  align="left"&gt;denk&lt;/td&gt;
 &lt;td  align="left"&gt;je&lt;/td&gt;
 &lt;td  align="left"&gt;dat&lt;/td&gt;
 &lt;td  align="left"&gt;ie&lt;/td&gt;
 &lt;td  align="left"&gt;zei,&lt;/td&gt;
 &lt;td  align="left"&gt;die&lt;/td&gt;
 &lt;td  align="left"&gt;prins?&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt; 
 &lt;td  align="left"&gt;and&lt;/td&gt;
 &lt;td  align="left"&gt;what&lt;/td&gt;
 &lt;td  align="left"&gt;think&lt;/td&gt;
 &lt;td  align="left"&gt;you&lt;/td&gt;
 &lt;td  align="left"&gt;that&lt;/td&gt;
 &lt;td  align="left"&gt;he&lt;/td&gt;
 &lt;td  align="left"&gt;said&lt;/td&gt;
 &lt;td  align="left"&gt;that&lt;/td&gt;
 &lt;td  align="left"&gt;prince&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
 &lt;td colspan="9"&gt;‘And what do you think this prince said?’&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

`denken + 2SG` 'think + 2SG' is very common, prototypical even.

This construction functions as a pragmatic appeal to the hearer, and can best be understood through the notion of prototypicality:
* descriptive adequacy
* explanatory power

---
class: center

# Cue validity vs category validity

.pull-left[
**cue validity**

&gt; Given that entity e exhibits property p, what is the probability that e is a member of category C?

If a creature (`e`) has wings (`p`), there is a high chance that it is a bird (`C`).

]

.pull-right[
**category validity**

&gt;Given that entity e is a member of category C, what is the probability that e will exhibit property p?

If a creature (`e`) is a bird (`C`), there is a high chance it has wings (`p`).

]

---
class: center

# Cue validity vs category validity

In regard to constructions this becomes:

.pull-left[
**Cue validity of words vis-à-vis constructions**

&gt; Given an occurrence of word w, what is the probability that w is part of construction C?

*cranberry* words like *dint*, which occurs in a fixed phrase *by dint of* in 92% of the cases.

But *by* is not a good indicator of this construction!

]

.pull-right[
**Category validity of constructions vis-à-vis the words that occur
in them**

&gt;Given the occurrence of construction C, what is the probability that word w features as part of C?

.left[
The Dutch Wh-extraction construction has high category validity: this construction very strongly predicts the occurrence of the main verb denken.

But, because *denken* is very frequent, the occurrence of the verb has virtually no predictive power vis-à-vis the construction!
]

]

---

# Other studies

* Stefanowitch and Gries (2003; Gries &amp; Stefanowitch 2004) with their `collostructions`
* Goldberg (2006) etc.

&gt;The picture that emerges from these studies is that **the syntax and lexicon of a language are closely intertwined and interdependent**. 
This links up with an important theme in Rosch’s work. One of Rosch’s “principles of categorization” is that an organism perceives a **“correlational structure”** in the world.

So, in general, Taylor concludes that:

&gt; Linguistic encoding of a situation involves the categorization of the situation in accordance with the available linguistic resources. 
Our discussion has suggested that categorization may play an even more fundamental role in language. 
The very structure of language itself is a matter of categorization. 
Rosch’s discoveries regarding the internal structure of categories are no less relevant to the **category of language** than they are to the **categories *symbolized* by language**.
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
