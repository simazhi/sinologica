<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>coding | Thomas Van Hoey | Sinologica</title>
    <link>/tags/coding/</link>
      <atom:link href="/tags/coding/index.xml" rel="self" type="application/rss+xml" />
    <description>coding</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© Thomas Van Hoey</copyright><lastBuildDate>Tue, 01 Oct 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>coding</title>
      <link>/tags/coding/</link>
    </image>
    
    <item>
      <title>Tidy collostructions</title>
      <link>/post/tidy-collostructions/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/post/tidy-collostructions/</guid>
      <description>


&lt;div id=&#34;tl-dr&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;tl ; dr&lt;/h1&gt;
&lt;p&gt;In this post I look at the family of &lt;a href=&#34;https://en.wikipedia.org/wiki/Collostructional_analysis&#34;&gt;collexeme analysis&lt;/a&gt; methods originated by Gries and Stefanowitsch.
Since they use a lot of Base R, and love using vectors, there is a hurdle that needs to be conquered if you are used to the rectangles in tidy data.
I first give an overview of what the method tries to do, and then at the end show the hurdle in detail, followed by the steps necessary to enable the computation of the desired variables and statistical tests (association measures).
Basically, you need to convert from pure tidy data to a tidy contingency format.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;So in order to finalize my database on Chinese ideophones, creatively entitled &lt;a href=&#34;https://osf.io/kpwgf/&#34;&gt;CHIDEOD&lt;/a&gt;, I decided to work through &lt;a href=&#34;http://www.stgries.info&#34;&gt;Stefan Gries&lt;/a&gt;’s &lt;em&gt;Quantitative corpus linguistics with R&lt;/em&gt; (2016; 2nd edition; &lt;a href=&#34;http://www.stgries.info/research/qclwr/qclwr.html&#34;&gt;companion website here&lt;/a&gt;).&lt;br /&gt;
That together with &lt;a href=&#34;http://www.natalialevshina.com&#34;&gt;Natalia Levshina&lt;/a&gt;’s &lt;em&gt;How to do linguistics with R&lt;/em&gt; (2015; 1st edition; &lt;a href=&#34;https://benjamins.com/sites/z.195/&#34;&gt;companion website here&lt;/a&gt;), which I worked through last June, has given me a lot of inspiration to tackle a number issues I have been struggling with, or at least thinking about without really knowing how to tackle them — I guess that counts as &lt;em&gt;struggling with&lt;/em&gt;.
By the way, it is locally kind of confirmed currently that Levshina will be a keynote speaker at our CLDC conference in May.
So you can already prepare those abstracts if you wish to attempt to present here in Taipei.&lt;/p&gt;
&lt;p&gt;Anyway, one of the more intriguing family of methods to investigate the relation between constructions and words that fill the slots is the family of collexeme analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-is-collexeme-analysis&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What is collexeme analysis?&lt;/h1&gt;
&lt;p&gt;As &lt;a href=&#34;https://doi.org/10.1075/ijcl.00011.gri&#34;&gt;Gries (2019)&lt;/a&gt; discusses, the methodology of collexeme analysis is an extension of the notions of a) &lt;em&gt;collocation&lt;/em&gt; (which words really belong together, e.g. &lt;em&gt;watch TV&lt;/em&gt; and &lt;em&gt;watch a movie&lt;/em&gt; will have a stronger collocational bond than &lt;em&gt;watch a powerpoint presentation&lt;/em&gt;, although the latter has become a weekly activity), and b) &lt;em&gt;colligation&lt;/em&gt; (what constructions belong together, e.g. &lt;em&gt;watch&lt;/em&gt; will typically be followed by a noun, although verb phrases like &lt;em&gt;watch him play&lt;/em&gt; also occur).&lt;/p&gt;
&lt;p&gt;So the basis of this method is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Contingency_table&#34;&gt;contingency table&lt;/a&gt; (or cross-table; or &lt;a href=&#34;https://nl.wikipedia.org/wiki/Kruistabel&#34;&gt;&lt;em&gt;kruistabel&lt;/em&gt;&lt;/a&gt; if you love Dutch; &lt;em&gt;lièlián biǎo&lt;/em&gt; 列聯表 in Chinese (apparently)).
Basically, something like this, that should look somewhat familiar:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Element 2&lt;/th&gt;
&lt;th&gt;Not element 2 / other elements&lt;/th&gt;
&lt;th&gt;Sum&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;Element 1 &lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;a&lt;/td&gt;
&lt;td&gt;b&lt;/td&gt;
&lt;td&gt;a + b&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;strong&gt;Not element 1 / other elements&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;c&lt;/td&gt;
&lt;td&gt;d&lt;/td&gt;
&lt;td&gt;c + d&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;Sum&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;a + c&lt;/td&gt;
&lt;td&gt;b + d&lt;/td&gt;
&lt;td&gt;a + b + c + d&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;These letters (a, b, c, d) play an important role in colloxeme analyses.
So stay tuned for that.&lt;/p&gt;
&lt;div id=&#34;approach-1-collexeme-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Approach 1: Collexeme analysis&lt;/h2&gt;
&lt;p&gt;So what &lt;a href=&#34;https://doi.org/10.1075/ijcl.8.2.03ste&#34;&gt;Stefanowitsch &amp;amp; Gries (2003)&lt;/a&gt; wanted to investigate was the [N &lt;em&gt;waiting to happen&lt;/em&gt;] construction, e.g. &lt;em&gt;an accident waiting to happen&lt;/em&gt;, &lt;em&gt;a disaster waiting to happen&lt;/em&gt; etc.
In this &lt;strong&gt;collexeme analysis&lt;/strong&gt; you are quantifying to what degree the words found in a corpus occur in that construction: are they attracted or repulsed, and by how much?&lt;/p&gt;
&lt;p&gt;In this scenario, element 1 is e.g. &lt;em&gt;an accident&lt;/em&gt;, and element 2 the construction &lt;em&gt;waiting to happen&lt;/em&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;em&gt;waiting to happen&lt;/em&gt;&lt;/th&gt;
&lt;th&gt;not &lt;em&gt;waiting to happen&lt;/em&gt;&lt;/th&gt;
&lt;th&gt;Sum&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;&lt;em&gt;an accident&lt;/em&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;a&lt;/td&gt;
&lt;td&gt;b&lt;/td&gt;
&lt;td&gt;a + b&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;not &lt;strong&gt;&lt;em&gt;an accident&lt;/em&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;c&lt;/td&gt;
&lt;td&gt;d&lt;/td&gt;
&lt;td&gt;c + d&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;Sum&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;a + c&lt;/td&gt;
&lt;td&gt;b + d&lt;/td&gt;
&lt;td&gt;a + b + c + d&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;approach-2-distinctive-collexeme-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Approach 2: Distinctive collexeme analysis&lt;/h2&gt;
&lt;p&gt;A year later, &lt;a href=&#34;https://doi.org/10.1075/ijcl.9.1.06gri&#34;&gt;Gries &amp;amp; Stefanowitsch (2004)&lt;/a&gt; extended the methodology to quantify to what degree the words prefer to appear in one of two constructions.
For example, the ditransitive &lt;em&gt;give him a call&lt;/em&gt; vs. the prepositional &lt;em&gt;give a call to him&lt;/em&gt;.
Here the table changes into:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;ditransitive&lt;/th&gt;
&lt;th&gt;prepositional&lt;/th&gt;
&lt;th&gt;Sum&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;&lt;em&gt;give&lt;/em&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;a&lt;/td&gt;
&lt;td&gt;b&lt;/td&gt;
&lt;td&gt;a + b&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;not &lt;strong&gt;&lt;em&gt;give&lt;/em&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;c&lt;/td&gt;
&lt;td&gt;d&lt;/td&gt;
&lt;td&gt;c + d&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;Sum&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;a + c&lt;/td&gt;
&lt;td&gt;b + d&lt;/td&gt;
&lt;td&gt;a + b + c + d&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;approach-3-co-varying-collexeme-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Approach 3: Co-varying collexeme analysis&lt;/h2&gt;
&lt;p&gt;The third seminal paper was published in the same year (Gries &amp;amp; Stefanowitsch 2004; ISBN: 9781575864648) sought to quantify the attraction / repulsion between two different slots in a construction, e.g. &lt;em&gt;trick … into buying&lt;/em&gt;, &lt;em&gt;force … into accepting&lt;/em&gt; etc.
For this, the table is adapted to:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;em&gt;accepting&lt;/em&gt;&lt;/th&gt;
&lt;th&gt;not &lt;em&gt;accepting&lt;/em&gt;&lt;/th&gt;
&lt;th&gt;Sum&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;&lt;em&gt;force&lt;/em&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;a&lt;/td&gt;
&lt;td&gt;b&lt;/td&gt;
&lt;td&gt;a + b&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;not &lt;strong&gt;&lt;em&gt;force&lt;/em&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;c&lt;/td&gt;
&lt;td&gt;d&lt;/td&gt;
&lt;td&gt;c + d&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;Sum&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;a + c&lt;/td&gt;
&lt;td&gt;b + d&lt;/td&gt;
&lt;td&gt;a + b + c + d&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;okay-i-get-that-table-stuff-what-next&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Okay, I get that table stuff, what next?&lt;/h2&gt;
&lt;p&gt;Let’s say you were able to get the frequencies from a corpus – I should probably mention that, &lt;code&gt;*cough* *cough*&lt;/code&gt; not everybody agrees with this kind of contingency tables, the overview paper by &lt;a href=&#34;https://doi.org/10.1075/ijcl.00011.gri&#34;&gt;Gries (2019)&lt;/a&gt; has plenty of interesting references and exciting rebuttals – and you have this table, possibly for lots of elements and/or constructions.&lt;/p&gt;
&lt;p&gt;We’ll keep an example here that I calculated with Gries’s (2016) book mentioned above.
One of the case studies looks at verbs that co-occur with the modal verb &lt;em&gt;must&lt;/em&gt;, e.g. &lt;em&gt;must accept&lt;/em&gt;, &lt;em&gt;must agree&lt;/em&gt;, &lt;em&gt;must confess&lt;/em&gt;, vs. how much these verbs occur with other modal verbs, e.g &lt;em&gt;should accept&lt;/em&gt;, &lt;em&gt;should agree&lt;/em&gt; etc.
So in this case, element 1 was a verb (&lt;em&gt;confess&lt;/em&gt;) and element 2 was &lt;em&gt;must&lt;/em&gt;; not-element-1 were all the other verbs, and not-element-2 were all the other modal verbs.&lt;/p&gt;
&lt;p&gt;The respective table from an abstract level looks like this:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;em&gt;must&lt;/em&gt;&lt;/th&gt;
&lt;th&gt;not &lt;em&gt;must&lt;/em&gt;&lt;/th&gt;
&lt;th&gt;Sum&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;&lt;em&gt;confess&lt;/em&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;a&lt;/td&gt;
&lt;td&gt;b&lt;/td&gt;
&lt;td&gt;a + b&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;not &lt;strong&gt;&lt;em&gt;confess&lt;/em&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;c&lt;/td&gt;
&lt;td&gt;d&lt;/td&gt;
&lt;td&gt;c + d&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;Sum&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;a + c&lt;/td&gt;
&lt;td&gt;b + d&lt;/td&gt;
&lt;td&gt;a + b + c + d&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;I got these frequencies from the BNC (as Gries shows in his book, but I used my tidyverse skills&lt;sup&gt;TM&lt;/sup&gt; to get them, so if they are slightly off, then it was because of not following his script completely):&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;em&gt;must&lt;/em&gt;&lt;/th&gt;
&lt;th&gt;not &lt;em&gt;must&lt;/em&gt;&lt;/th&gt;
&lt;th&gt;Sum&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;&lt;em&gt;confess&lt;/em&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;not &lt;strong&gt;&lt;em&gt;confess&lt;/em&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1990&lt;/td&gt;
&lt;td&gt;62114&lt;/td&gt;
&lt;td&gt;64104&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;Sum&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;2001&lt;/td&gt;
&lt;td&gt;62115&lt;/td&gt;
&lt;td&gt;64116&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Or in a Base R table:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- 11
b &amp;lt;- 1
c &amp;lt;- 1990
d &amp;lt;- 62114

confess &amp;lt;- c(a, b)
notconfess &amp;lt;- c(c, d)

must.table &amp;lt;- rbind(confess, notconfess) 
colnames(must.table) &amp;lt;- c(&amp;quot;must&amp;quot;, &amp;quot;notmust&amp;quot;)
must.table&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            must notmust
## confess      11       1
## notconfess 1990   62114&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What do you do now?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Now it’s time for letter math!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The association measure (read: statistical test) that Gries &amp;amp; Stefanowitsch, as well as others, have used most is the &lt;a href=&#34;https://en.wikipedia.org/wiki/Fisher%27s_exact_test&#34;&gt;Fisher Yates Exact test&lt;/a&gt;, and more precisely the negative &lt;span class=&#34;math inline&#34;&gt;\(log10\)&lt;/span&gt; of its &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value.
Underlying this (see the link in this paragraph) are calculations using those letter cells (a,b,c,d).
Luckily we don’t need to do that manually because R has a function for this – &lt;code&gt;fischer.test()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fisher.test(must.table)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Fisher&amp;#39;s Exact Test for Count Data
## 
## data:  must.table
## p-value = 3.106e-16
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##     49.90447 13241.49567
## sample estimates:
## odds ratio 
##   344.6593&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So as you can see the pvalue is 3.105600710^{-16}.
If we take the negative &lt;span class=&#34;math inline&#34;&gt;\(log10\)&lt;/span&gt; of this, it becomes 15.5078544, which gives us the result we expected.&lt;/p&gt;
&lt;p&gt;An easier way of computing the Fisher Yates Exact test of this table is by using the letter math and the &lt;code&gt;pv.Fischer.collostr&lt;/code&gt; function provided by Levshina’s &lt;code&gt;Rling&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Rling::pv.Fisher.collostr(a, b, c, d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.105601e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Other tests that have been proposed are so-called Reliance and Attraction (cf. &lt;a href=&#34;doi.org/10.1515/cog-2013-0018&#34;&gt;Schmid &amp;amp; Küchenhoff 2013&lt;/a&gt; a.o.).
Reliance is the relative frequency of a verb (&lt;em&gt;confess&lt;/em&gt;) with &lt;em&gt;must&lt;/em&gt; with regard to all uses of the given verb; Attraction is the relative frequency of a verb (&lt;em&gt;confess&lt;/em&gt;) with &lt;em&gt;must&lt;/em&gt; based on all usages with &lt;em&gt;must&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Reliance = \frac{a}{a+b}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Attraction = \frac{a}{a+c} \]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;attraction &amp;lt;- a / (a+c) * 100
reliance &amp;lt;- a / (a+b) * 100&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Attraction of confess and must is 0.5497251 and the Reliance is 91.6666667.
This high Reliance means that whenever &lt;em&gt;confess&lt;/em&gt; occurs in the corpus after a modal it &lt;em&gt;relies&lt;/em&gt; on &lt;em&gt;must&lt;/em&gt; to occur.
Its Attraction, however, has a much lower value: &lt;em&gt;must&lt;/em&gt; does not necessarily occur with &lt;em&gt;confess&lt;/em&gt;, in fact, it occurs with lots of other verbs as well!&lt;/p&gt;
&lt;p&gt;The third group of tests is actually correlated to Attraction and Reliance: respectively &lt;span class=&#34;math inline&#34;&gt;\(\Delta P_{word \to construction}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\Delta P_{construction \to word}\)&lt;/span&gt; (cf. &lt;a href=&#34;doi.org/10.1075/arcl.7.08ell&#34;&gt;Ellis &amp;amp; Ferreira-Junior&lt;/a&gt; a.o.).
They are also known as tests of cue validity and are calculated as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\Delta P_{word \to construction} = cue_{construction} = \frac{a}{a + c} - \frac{b}{b + d}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\Delta P_{construction \to word} = cue_{verb} = \frac{a}{a + b} - \frac{c}{c + d}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dP.cueCx &amp;lt;- a/(a + c) - b/(b + d)
dP.cueVerb &amp;lt;- a/(a + b) - c/(c + d)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So the &lt;span class=&#34;math inline&#34;&gt;\(\Delta P_{word \to construction}\)&lt;/span&gt; of &lt;em&gt;must confess&lt;/em&gt; is 0.0054812
and the &lt;span class=&#34;math inline&#34;&gt;\(\Delta P_{construction \to word}\)&lt;/span&gt; of &lt;em&gt;must confess&lt;/em&gt; is 0.8856234, so these numbers look a lot like those of Attraction and Reliance.&lt;/p&gt;
&lt;p&gt;Anyway, I think you get the drift: if you have the contingency table, you choose an association measure (there are more than these three sets) and analyze the results.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;tidy-collostructions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tidy collostructions&lt;/h1&gt;
&lt;p&gt;So if that’s so clear, why am I writing this post?
For me, the main difficulty with the approach is that Gries and Levshina love writing things in Base R (Gries even more than Levshina).
But to someone who really started to appreciate R after the tidyverse became more available, there is this dissonance with the way they go about things.&lt;/p&gt;
&lt;p&gt;One of the biggest difference is the obsessive-compulsion of tidyverse to think in rectangles, a.k.a. dataframes or tibbles, rather than the vector( letter)s that Gries and Levshina love using, especially in their letter mathematics.&lt;/p&gt;
&lt;p&gt;As a consequence of this “&lt;a href=&#34;https://www.youtube.com/watch?v=GapSskrtUzU&#34;&gt;rectangling&lt;/a&gt;” and tidy format (long and skinny), rather than contingency format (2 x 2), it is challenging to compute even basic chisquare.tests.&lt;/p&gt;
&lt;p&gt;So in Base R, a chisquare is easy to compute, but then hard to continue working with, because this thick text block is given and you can’t really access the contents (but there are solutions, like &lt;code&gt;broom::tidy&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;chisq.test(must.table)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in chisq.test(must.table): Chi-squared approximation may be
## incorrect&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s Chi-squared test with Yates&amp;#39; continuity correction
## 
## data:  must.table
## X-squared = 282.63, df = 1, p-value &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In a tidy format, you typically have to jump through a lot of hoops to either get to use the same function or use one of the newer alternative functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
must.tibble &amp;lt;- tribble(
  ~ verb, ~ must, ~notmust,
  &amp;quot;confess&amp;quot;, 11, 1,
  &amp;quot;notconfess&amp;quot;, 1990, 62114
)
must.tibble %&amp;gt;% kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
verb
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
must
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
notmust
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
confess
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
notconfess
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1990
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
62114
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# this function will give you bad output
# so you can&amp;#39;t just simply do this
chisq.test(must.tibble$must, must.tibble$notmust)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in chisq.test(must.tibble$must, must.tibble$notmust): Chi-squared
## approximation may be incorrect&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s Chi-squared test with Yates&amp;#39; continuity correction
## 
## data:  must.tibble$must and must.tibble$notmust
## X-squared = 0, df = 1, p-value = 1&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;hoop-1-make-it-really-tidy&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hoop 1: make it really tidy&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;must.tibble %&amp;gt;%
  pivot_longer(cols = c(must, notmust),
               names_to = &amp;quot;modal&amp;quot;,
               values_to = &amp;quot;n&amp;quot;) %&amp;gt;% # now it is really tidy
  kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
verb
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
modal
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
n
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
confess
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
must
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
confess
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
notmust
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
notconfess
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
must
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1990
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
notconfess
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
notmust
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
62114
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;hoop-2-uncount&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hoop 2: uncount&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;must.tibble %&amp;gt;%
  pivot_longer(cols = c(must, notmust),
               names_to = &amp;quot;modal&amp;quot;,
               values_to = &amp;quot;n&amp;quot;) %&amp;gt;% # now it is really tidy
  uncount(n)  # uncount&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 64,116 x 2
##    verb    modal
##    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;
##  1 confess must 
##  2 confess must 
##  3 confess must 
##  4 confess must 
##  5 confess must 
##  6 confess must 
##  7 confess must 
##  8 confess must 
##  9 confess must 
## 10 confess must 
## # … with 64,106 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;hoop-3-convert-to-table&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hoop 3: convert to table&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;must.tibble %&amp;gt;%
  pivot_longer(cols = c(must, notmust),
               names_to = &amp;quot;modal&amp;quot;,
               values_to = &amp;quot;n&amp;quot;) %&amp;gt;% # now it is really tidy
  uncount(n)  %&amp;gt;% # uncount
  table() # turn to Base R table&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             modal
## verb          must notmust
##   confess       11       1
##   notconfess  1990   62114&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;hoop-4-chisquare&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hoop 4: chisquare&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;must.tibble %&amp;gt;%
  pivot_longer(cols = c(must, notmust),
               names_to = &amp;quot;modal&amp;quot;,
               values_to = &amp;quot;n&amp;quot;) %&amp;gt;% # now it is really tidy
  uncount(n)  %&amp;gt;% # uncount
  table() %&amp;gt;% # turn to Base R table
  chisq.test() &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in chisq.test(.): Chi-squared approximation may be incorrect&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s Chi-squared test with Yates&amp;#39; continuity correction
## 
## data:  .
## X-squared = 282.63, df = 1, p-value &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;hoop-5-tidy-with-broom&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hoop 5: &lt;code&gt;tidy&lt;/code&gt; with &lt;code&gt;broom&lt;/code&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;must.tibble %&amp;gt;%
  pivot_longer(cols = c(must, notmust),
               names_to = &amp;quot;modal&amp;quot;,
               values_to = &amp;quot;n&amp;quot;) %&amp;gt;% # now it is really tidy
  uncount(n)  %&amp;gt;% # uncount
  table() %&amp;gt;% # turn to Base R table
  chisq.test()%&amp;gt;%
  broom::tidy() %&amp;gt;%
  kable()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in chisq.test(.): Chi-squared approximation may be incorrect&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
statistic
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
p.value
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
parameter
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
method
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
282.6321
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pearson’s Chi-squared test with Yates’ continuity correction
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;I know there are some tidyverse-friendly functions like &lt;code&gt;infer::chisq_test&lt;/code&gt;, but it seems to lack arguments like expected values (&lt;code&gt;chisq.test()$exp&lt;/code&gt;).
So this awkward hoop jumping is annoying but gets the job done (for now?).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;from-tidy-to-contingency&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;From tidy to contingency&lt;/h2&gt;
&lt;p&gt;Anyway, while for most summary statistics a tidy format (see hoop 1) is the easiest to work with, I don’t think it’s very intuitive for the association measures paradigm.&lt;/p&gt;
&lt;p&gt;So in this working example of &lt;em&gt;must + V_inf_&lt;/em&gt; construction what I did was get all the occurrences of all modal verbs + verbs in the infinitive from the BNC corpus.
The second step I did was add a column with &lt;code&gt;dplyr::case_when&lt;/code&gt; to identify if a modal verb was &lt;em&gt;must&lt;/em&gt; or another modal verb.&lt;/p&gt;
&lt;p&gt;Let’s look at this data shall we:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.must&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 64,116 x 3
##    modal  verb      mod.type
##    &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;   
##  1 can    find      OTHER   
##  2 should stop      OTHER   
##  3 should recognise OTHER   
##  4 will   cost      OTHER   
##  5 might  think     OTHER   
##  6 can    sink      OTHER   
##  7 can    change    OTHER   
##  8 must   help      MUST    
##  9 ll     help      OTHER   
## 10 ll     take      OTHER   
## # … with 64,106 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see there are 64116 rows, and the table is just a count away form being tidy.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy.df.must &amp;lt;- df.must %&amp;gt;%
  count(mod.type, verb, sort = TRUE)
tidy.df.must&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2,522 x 3
##    mod.type verb      n
##    &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;
##  1 OTHER    get    3750
##  2 OTHER    go     3421
##  3 OTHER    see    2409
##  4 OTHER    take   2056
##  5 OTHER    like   1778
##  6 OTHER    say    1647
##  7 OTHER    come   1460
##  8 OTHER    make   1383
##  9 OTHER    give   1245
## 10 OTHER    put    1162
## # … with 2,512 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Much ‘prettier’, but what next?
This is actually the mental step I struggled the most with, this dissonance between tidy and contingency.
However, since we coded &lt;code&gt;mod.type&lt;/code&gt; with a binary value: “OTHER” or “MUST”, it is actually trivial to &lt;code&gt;dplyr::spread&lt;/code&gt; or &lt;code&gt;dplyr::pivot_wider&lt;/code&gt; them to a “tidy contingency table”:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spread.tidy.df.must &amp;lt;- tidy.df.must %&amp;gt;%
  pivot_wider(values_from = n,
              names_from = mod.type) 
spread.tidy.df.must&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2,113 x 3
##    verb  OTHER  MUST
##    &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
##  1 get    3750   102
##  2 go     3421    94
##  3 see    2409    14
##  4 take   2056    63
##  5 like   1778     3
##  6 say    1647   105
##  7 come   1460    41
##  8 make   1383    62
##  9 give   1245    22
## 10 put    1162    18
## # … with 2,103 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hey, this looks a lot like those schematic tables we had at the beginning!
But now the real challenge is to turn these numbers into the letters a, b, c, and d, so we can perform our letter math.&lt;/p&gt;
&lt;p&gt;After changing all numeric values we have to doubles (instead of integers) and changing all NAs to 0, we can get the letters by following simple arithmetic from our original schematic table, e.g. if we know a and a+c, then c = a+c - a etc.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Element 2&lt;/th&gt;
&lt;th&gt;Not element 2 / other elements&lt;/th&gt;
&lt;th&gt;Sum&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;Element 1 &lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;a&lt;/td&gt;
&lt;td&gt;b&lt;/td&gt;
&lt;td&gt;a + b&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;strong&gt;Not element 1 / other elements&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;c&lt;/td&gt;
&lt;td&gt;d&lt;/td&gt;
&lt;td&gt;c + d&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;Sum&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;a + c&lt;/td&gt;
&lt;td&gt;b + d&lt;/td&gt;
&lt;td&gt;a + b + c + d&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spread.tidy.df.must %&amp;gt;%
  mutate_if(is.numeric, ~ as.double(.x)) %&amp;gt;% # we&amp;#39;ll want doubles instead of integers
  mutate_if(is.numeric, ~ replace_na(.x, 0)) %&amp;gt;% # NAs should be 0
  
  mutate(a = MUST,
       ac = sum(MUST),
       c = ac - a,
       ab = MUST + OTHER,
       b = ab - a,
       abcd = sum(MUST, OTHER),
       d = abcd - a - b -c,
       aExp = (a + b)*(a + c)/(a + b + c + d)) -&amp;gt; abcd.must
abcd.must&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2,113 x 11
##    verb  OTHER  MUST     a    ac     c    ab     b  abcd     d  aExp
##    &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 get    3750   102   102  2001  1899  3852  3750 64116 58365 120. 
##  2 go     3421    94    94  2001  1907  3515  3421 64116 58694 110. 
##  3 see    2409    14    14  2001  1987  2423  2409 64116 59706  75.6
##  4 take   2056    63    63  2001  1938  2119  2056 64116 60059  66.1
##  5 like   1778     3     3  2001  1998  1781  1778 64116 60337  55.6
##  6 say    1647   105   105  2001  1896  1752  1647 64116 60468  54.7
##  7 come   1460    41    41  2001  1960  1501  1460 64116 60655  46.8
##  8 make   1383    62    62  2001  1939  1445  1383 64116 60732  45.1
##  9 give   1245    22    22  2001  1979  1267  1245 64116 60870  39.5
## 10 put    1162    18    18  2001  1983  1180  1162 64116 60953  36.8
## # … with 2,103 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So now we can easily perform all of the association measures we want, and rank them accordingly.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fischer-yates-exact&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fischer Yates Exact&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fye &amp;lt;- abcd.must %&amp;gt;%
  mutate(fye = Rling::pv.Fisher.collostr(a, b, c, d)) %&amp;gt;%
  #filter(verb == &amp;quot;confess&amp;quot;) %&amp;gt;%
  mutate(negfye = case_when(a &amp;lt; aExp ~ format(round(log10(fye)), nsmall = 2),
                            TRUE ~ format(round(- log10(fye)), nsmall = 2)),
         negfye = as.double(negfye)) %&amp;gt;% #I did some rounding
  arrange(desc(negfye)) %&amp;gt;%
  select(verb, OTHER, MUST, fye, negfye)

fye %&amp;gt;% top_n(20) %&amp;gt;% kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
verb
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
OTHER
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
MUST
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
fye
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
negfye
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
admit
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
159
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
225
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
confess
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
say
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1647
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
105
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
realise
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
recognise
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
know
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
432
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000001
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
remember
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
324
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
rank
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000001
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
decide
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
120
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000014
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
pay
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
354
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000052
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
wait
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
139
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000307
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
ensure
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000243
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
inform
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000065
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
stress
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000065
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
apologise
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0001186
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
obey
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0002895
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
look
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
560
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0017845
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
feel
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
223
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
18
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0006318
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
act
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0014017
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
assume
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0018726
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
reflect
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0018726
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
mention
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0015902
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
emerge
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0016252
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
own
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0005395
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
emphasise
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0030892
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
register
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0030892
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
balance
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0022137
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
realize
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0022137
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
respect
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0005656
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
comply
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0028599
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
exhibit
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0028599
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
export
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0009735
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
outperform
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0009735
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fye %&amp;gt;% arrange(negfye) %&amp;gt;% top_n(-20) %&amp;gt;% kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
verb
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
OTHER
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
MUST
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
fye
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
negfye
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
like
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1778
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-20
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
see
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2409
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-18
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
hear
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
428
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000021
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-6
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
help
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
820
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000185
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-5
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
want
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
401
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000074
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-5
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
tell
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
985
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0003130
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-4
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
give
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1245
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0031496
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
put
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1162
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
18
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0006828
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
need
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
461
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0018961
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
lead
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
321
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0009838
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
imagine
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
290
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0019299
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
call
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
268
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0003216
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
cause
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
211
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0022792
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
buy
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
402
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0090712
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
play
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
340
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0291563
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
happen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
335
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0039267
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
afford
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
205
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0035887
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
receive
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
205
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0242516
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
pick
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
203
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0239273
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
appear
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
187
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0049951
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
benefit
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
147
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0160195
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;attraction-reliance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Attraction, Reliance&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;abcd.must %&amp;gt;%
  mutate(attraction = a / (a+c) * 100,
         reliance = a / (a+b) * 100) %&amp;gt;%
  arrange(desc(attraction)) %&amp;gt;%
  top_n(20) %&amp;gt;%
  select(verb, OTHER, MUST, attraction, reliance) %&amp;gt;%
  kable()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Selecting by reliance&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
verb
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
OTHER
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
MUST
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
attraction
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
reliance
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
export
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.099950
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
outperform
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.099950
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
acquaint
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
capitalise
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
capitulate
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
class
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
combat
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
comfort
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
discard
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
dissociate
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
dread
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
enclose
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
graft
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
interrogate
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
itch
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
nurture
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
plagiarise
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
protrude
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
rediscover
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
redouble
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
shoulder
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
shrive
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
stipulate
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.049975
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;delta-p&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Delta P&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;abcd.must %&amp;gt;%
  mutate(dP.cueCx = a/(a + c) - b/(b + d),
         dP.cueVerb = a/(a + b) - c/(c + d)) %&amp;gt;%
  arrange(desc(dP.cueCx)) %&amp;gt;%
  select(verb,  OTHER, MUST, dP.cueCx, dP.cueVerb) %&amp;gt;%
  top_n(20) %&amp;gt;%
  kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
verb
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
OTHER
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
MUST
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
dP.cueCx
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
dP.cueVerb
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
export
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0009995
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688212
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
outperform
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0009995
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688212
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
acquaint
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
capitalise
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
capitulate
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
class
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
combat
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
comfort
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
discard
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
dissociate
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
dread
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
enclose
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
graft
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
interrogate
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
itch
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
nurture
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
plagiarise
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
protrude
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
rediscover
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
redouble
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
shoulder
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
shrive
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
stipulate
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004998
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9688061
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;It is perfectly possible to perform association measures starting with a tidy dataframe.
First you need to spread out with a binary variable, to make it a tidy contingency table.
Then you can identify a, b, c, and d.
Next you can chooose your preferred statistical test, rank verbs, and try to interpret the findings.&lt;/p&gt;
&lt;p&gt;I should probably also mention that Gries is has been advocating to not just use one association measure, but three or more.
Using just two, you can plot like Attraction and Reliance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;abcd.must %&amp;gt;%
  mutate(attraction = a / (a+c) * 100,
         reliance = a / (a+b) * 100) %&amp;gt;%
  arrange(desc(attraction)) %&amp;gt;%
  select(verb, OTHER, MUST, attraction, reliance) %&amp;gt;%
  ggplot(aes(x = attraction, 
             y = reliance)) +
   geom_point() +
  gghighlight::gghighlight(attraction &amp;gt; 2 | 50 &amp;lt; reliance &amp;amp; reliance &amp;lt; 100,
                           label_key = verb) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-01-tidy-collostructions-some-ideas_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Guanguan goes the Chinese Word Segmentation (II)</title>
      <link>/post/guanguan-goes-the-chinese-word-segmentation-2/</link>
      <pubDate>Wed, 11 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/post/guanguan-goes-the-chinese-word-segmentation-2/</guid>
      <description>

&lt;h1 id=&#34;tl-dr&#34;&gt;tl; dr&lt;/h1&gt;

&lt;p&gt;This double blog is first about the opening line of the &lt;em&gt;Book of Odes&lt;/em&gt;, and later about how to deal with Chinese word segmentation, and my current implementation of it. So if you&amp;rsquo;re only &lt;a href=&#34;../guanguan-goes-the-chinese-word-segmentation-2&#34;&gt;interested in the computational part, look at the next one&lt;/a&gt;. If, on the other hand, you want to know more about my views on the translation of &lt;em&gt;guān guān&lt;/em&gt; etc., &lt;a href=&#34;../guanguan-goes-the-chinese-word-segmentation&#34;&gt;look at the first part&lt;/a&gt;.
In this part I use different approaches from a mostly R-centred focus to look at word segmentation in Chinese.&lt;/p&gt;

&lt;h1 id=&#34;intro-quick-recap&#34;&gt;Intro - quick recap&lt;/h1&gt;

&lt;p&gt;The issues that prompted me to write the previous post are twofold.
On the one hand, I came across a translation of the first line of the &lt;em&gt;Book of Odes&lt;/em&gt; (&lt;em&gt;Shījīng&lt;/em&gt; 詩經) and subsequent critiques of that translation.
I decided to give my take on the extensive coverage of the first stanza.
Here is the first line as it is transmitted to us, as well with a translation I made.
(By the way, if you can provide a better translation, please bring it on.)&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;關關雎鳩，&lt;br /&gt;
在河之洲。&lt;br /&gt;
窈窕淑女，&lt;br /&gt;
君子好逑。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Krōn, krōn&lt;/em&gt; the físh-hawks cáll,&lt;br /&gt;
ón the íslet ín the ríver.&lt;br /&gt;
délicáte, demúre, young lády,&lt;br /&gt;
fór the lórd a góód mate shé.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;On the other hand, I have been reading up on how to deal with Chinese from a corpus linguistics point-of-view.
And that means also looking at how Natural Language Processing &amp;ndash; the next-door-neighbour of corpus linguistics &amp;ndash; deals with these issues.
To see why they are next-door-neighbours and not the same, you can read Gries&amp;rsquo;s (2011) &amp;ldquo;Methodological and interdisciplinary stance in Corpus Linguistics&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Anyway, there are &lt;em&gt;a lot&lt;/em&gt; of things you can do with corpora, also in Chinese, but in general there are a few steps you need to do before you can even begin analyzing linguistic data and throwing different models at the data.&lt;/p&gt;

&lt;h1 id=&#34;steps-involved-in-text-analysis&#34;&gt;Steps involved in text analysis&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;10.1080/19312458.2017.1387238&#34; target=&#34;_blank&#34;&gt;Welbers et al. (2017)&lt;/a&gt; discuss the steps generally involved in text analysis, with a particular focus on &lt;a href=&#34;https://www.r-project.org&#34; target=&#34;_blank&#34;&gt;R&lt;/a&gt;.
These can be subsumed in three groups of tasks, and are exemplified with some R packages that may do the trick for that particular task.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/2019/Welbers2017.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;But&lt;/strong&gt;, what they forgot is that not every language comes with nicely defined space between the units (not necessarily words, because that concept is also a bit fuzzy).
Chinese and Japanese are prime examples of this phenomenon.
A really quick google search led me to this &lt;a href=&#34;https://www.quora.com/What-are-the-main-differences-between-NLP-for-Chinese-vs-NLP-for-English&#34; target=&#34;_blank&#34;&gt;Quora post where they asked what the differences are between Chinese and English NLP (Natural Language Processing)&lt;/a&gt;, and the answers, provided a certain Chier Hu are pretty good (&lt;a href=&#34;https://qr.ae/TWKny4&#34; target=&#34;_blank&#34;&gt;check it out yo&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;What I&amp;rsquo;m trying to get at here is that you need to break up long strings of Chinese first before you can even about putting things in the language modelling mixer.
So &lt;strong&gt;below I am going to discuss a bit how I went about SEGMENTATION in the past, what some alternatives are, and what I&amp;rsquo;m doing now.&lt;/strong&gt;
&lt;strong&gt;If you have any suggestions to improve this workflow, please contact me!&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;alternatives&#34;&gt;Alternatives&lt;/h1&gt;

&lt;h2 id=&#34;the-monosyllabic-approach&#34;&gt;The monosyllabic approach&lt;/h2&gt;

&lt;p&gt;What I&amp;rsquo;m looking for is actually not just a segmentation tool for Modern Chinese (which is difficult enough), but I want one that also works for Classical Chinese / Old Chinese.
The easiest option is to go with the idea that Classical Chinese is &lt;em&gt;mostly&lt;/em&gt; monosyllabic (one syllable = one character = one word).
If that is true, you can just go with the Julia Silge&amp;rsquo;s brilliant &lt;code&gt;tidytext&lt;/code&gt; package (&lt;a href=&#34;https://www.tidytextmining.com&#34; target=&#34;_blank&#34;&gt;see free e-book here&lt;/a&gt;), and set your &lt;code&gt;token = &amp;quot;characters&amp;quot;&lt;/code&gt;.
That this is a possible venue is shown here by a certain jjon987, &lt;a href=&#34;http://jjohn987.rbind.io/post/a-quasi-tidytext-analysis-of-3-chinese-classics/&#34; target=&#34;_blank&#34;&gt;who does an exploratory analysis of some classics in Chinese&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I would give that an A for exploratory analysis, but a B for segmentation.
That is because what I&amp;rsquo;m looking for, is something that is able to also deal with polysyllabic words like ideophones, e.g. &lt;em&gt;guānguān&lt;/em&gt; 關關 and &lt;em&gt;yáotiáo&lt;/em&gt; 窈窕, or polysyllabic monomorphemes like &lt;em&gt;jūnzi&lt;/em&gt; 君子, all present in this first stanza of the &lt;em&gt;Shījīng&lt;/em&gt;.
So we need something a bit more sophisiticated.&lt;/p&gt;

&lt;h2 id=&#34;stringi-based-approaches&#34;&gt;&lt;code&gt;stringi&lt;/code&gt; based approaches&lt;/h2&gt;

&lt;p&gt;Both the &lt;a href=&#34;https://quanteda.io/index.html&#34; target=&#34;_blank&#34;&gt;quanteda&lt;/a&gt; package and the &lt;a href=&#34;https://cran.r-project.org/web/packages/corpus/vignettes/corpus.html&#34; target=&#34;_blank&#34;&gt;corpus&lt;/a&gt; package do make use of the &lt;code&gt;stringi&lt;/code&gt; package to deal with the segmentation of Japanese and/or Chinese.
For an implementation of &lt;code&gt;quanteda&lt;/code&gt; on Japanese, I really recommend looking at &lt;a href=&#34;https://koheiw.net/?p=339&#34; target=&#34;_blank&#34;&gt;Kohei Watanabe&amp;rsquo;s post&lt;/a&gt;; for the instructions regarding &lt;code&gt;corpus&lt;/code&gt;, &lt;a href=&#34;https://cran.r-project.org/web/packages/corpus/vignettes/chinese.html&#34; target=&#34;_blank&#34;&gt;look here&lt;/a&gt;.
Because I&amp;rsquo;m most familiar with the &lt;code&gt;quanteda&lt;/code&gt; package and its functions, and because the underlying mechenism is the same, I&amp;rsquo;m only going to discuss this package below in &amp;ldquo;the test&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;(I think &lt;code&gt;tidytext&lt;/code&gt;&amp;rsquo;s &lt;code&gt;token = &amp;quot;words&amp;quot;&lt;/code&gt; also uses &lt;code&gt;stringi&lt;/code&gt; but I&amp;rsquo;m not sure.)&lt;/p&gt;

&lt;h2 id=&#34;oldies-but-goldies&#34;&gt;oldies but goldies&lt;/h2&gt;

&lt;p&gt;The package most people are familiar with is probably &lt;code&gt;jieba&lt;/code&gt; (&lt;a href=&#34;https://qinwenfeng.com/jiebaR/&#34; target=&#34;_blank&#34;&gt;R version&lt;/a&gt; and &lt;a href=&#34;https://github.com/fxsjy/jieba&#34; target=&#34;_blank&#34;&gt;python version&lt;/a&gt;).
This tends to work pretty well, but to be honest, it has always worked better for me in python, especially when I want to add custom dictionaries.
About those dictionaries, I don&amp;rsquo;t know why, but often they are not enforced, and that is actually a dealbreaker for me.
Word on the street also has it that it works much better for Simplfied Chinese than for Traditional Chinese, but I haven&amp;rsquo;t subjected this to tests myself.&lt;/p&gt;

&lt;h2 id=&#34;recent-approaches&#34;&gt;recent approaches&lt;/h2&gt;

&lt;p&gt;These last few years &lt;a href=&#34;http://nlpprogress.com/chinese/chinese_word_segmentation.html&#34; target=&#34;_blank&#34;&gt;numerous models have been introduced&lt;/a&gt;, each outperforming the previous one by one percent or so.
However, I wonder how much (corpus) linguists would agree with the standards from NLP &amp;ndash; there still seems to be a slightly more critical approach to the foundations of the issues.&lt;/p&gt;

&lt;p&gt;That being said, most of these newer models include datasets that have benefited from neural networks etc. The &lt;a href=&#34;https://bnosac.github.io/udpipe/docs/doc1.html&#34; target=&#34;_blank&#34;&gt;udpipe&lt;/a&gt; package brands itself as belonging to that category, and is thus worth exploring, especially since they have &lt;code&gt;classical_chinese-kyoto&lt;/code&gt; dataset that can help you segment and tokenize your data.
I&amp;rsquo;m curious if they can live up to the promises they make.&lt;/p&gt;

&lt;h2 id=&#34;python-integrated-approaches&#34;&gt;python-integrated approaches&lt;/h2&gt;

&lt;p&gt;Last but not least is the group of R-and-python interfacing packages, all made possible (to me at least) through the &lt;a href=&#34;https://rstudio.github.io/reticulate/&#34; target=&#34;_blank&#34;&gt;reticulate package&lt;/a&gt;.
With this I can basically run python from inside one of my R (markdown) scripts, and thus get the best of both worlds.
It&amp;rsquo;s a bit of a hassle to set up at first, but if you manage to do it, the rewars are pretty sweet.&lt;/p&gt;

&lt;p&gt;As for &lt;del&gt;packages&lt;/del&gt; libraries (python lingo), the &lt;a href=&#34;https://github.com/fxsjy/jieba&#34; target=&#34;_blank&#34;&gt;jieba library&lt;/a&gt; works pretty well.
But last week the CKIP team at Academia Sinica came out with this new tagging system, creatively called &lt;a href=&#34;https://github.com/ckiplab/ckiptagger&#34; target=&#34;_blank&#34;&gt;ckiptagger&lt;/a&gt;.
At first sight, this one does seem to be able to enforce a dictionary, so maybe this is the one I want to be using.
Let&amp;rsquo;s take these for a spin.&lt;/p&gt;

&lt;h1 id=&#34;setting-up-the-workspace-and-test-materials&#34;&gt;Setting up the workspace and test materials&lt;/h1&gt;

&lt;p&gt;So in this part I want to showcase a bit how different packages treat the question of segmentation.&lt;/p&gt;

&lt;h2 id=&#34;loading-in-the-required-libraries&#34;&gt;Loading in the required libraries&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tidyverse) #general catch-all of the tidyverse
library(quanteda)
library(tidytext)
library(jiebaR)
library(udpipe)

# python setup
library(reticulate)
use_python(&amp;quot;/usr/local/bin/python3&amp;quot;, required = T)
reticulate::py_config()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## python:         /usr/local/bin/python3
## libpython:      /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/config-3.7m-darwin/libpython3.7.dylib
## pythonhome:     /Library/Frameworks/Python.framework/Versions/3.7:/Library/Frameworks/Python.framework/Versions/3.7
## version:        3.7.0 (v3.7.0:1bf9cc5093, Jun 26 2018, 23:26:24)  [Clang 6.0 (clang-600.0.57)]
## numpy:          /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy
## numpy_version:  1.17.1
## 
## NOTE: Python version was forced by use_python function
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;test-material&#34;&gt;Test material&lt;/h2&gt;

&lt;p&gt;As test material I just care about this stanza from the &lt;em&gt;Shījīng&lt;/em&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;test &amp;lt;- c(&amp;quot;關關雎鳩、在河之洲。&amp;quot;,
          &amp;quot;窈窕淑女、君子好逑。&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Expected output:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;關關 雎鳩 、 在 河 之 洲 。
窈窕 淑女 、 君子 好 逑 。
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;tidytext&#34;&gt;&lt;code&gt;tidytext&lt;/code&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;test %&amp;gt;%
  tibble(.name_repair = ~ &amp;quot;lines&amp;quot;) %&amp;gt;%
  unnest_tokens(word, lines, token = &amp;quot;words&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 9 x 1
##   word    
##   &amp;lt;chr&amp;gt;   
## 1 關關    
## 2 雎鳩    
## 3 在      
## 4 河      
## 5 之      
## 6 洲      
## 7 窈窕淑女
## 8 君子    
## 9 好逑
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;test %&amp;gt;%
  tibble(.name_repair = ~ &amp;quot;lines&amp;quot;) %&amp;gt;%
  unnest_tokens(word, lines, token = &amp;quot;characters&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 16 x 1
##    word 
##    &amp;lt;chr&amp;gt;
##  1 關   
##  2 關   
##  3 雎   
##  4 鳩   
##  5 在   
##  6 河   
##  7 之   
##  8 洲   
##  9 窈   
## 10 窕   
## 11 淑   
## 12 女   
## 13 君   
## 14 子   
## 15 好   
## 16 逑
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Changing the argument &lt;code&gt;token&lt;/code&gt; from &lt;code&gt;&amp;quot;words&amp;quot;&lt;/code&gt; to &lt;code&gt;&amp;quot;characters&amp;quot;&lt;/code&gt; shows that neither is the ideal output.
The first one does capture most of the disyllabic words (=good) but the problem really lies with the phrase 窈窕淑女, which is treated as one block in the first and as four pieces in the second.
Technically you can do more collocationwise with the second, but that&amp;rsquo;s not what I&amp;rsquo;m after here.&lt;/p&gt;

&lt;h2 id=&#34;quanteda&#34;&gt;&lt;code&gt;quanteda&lt;/code&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;quanteda.corpus &amp;lt;- corpus(test)
tokens(quanteda.corpus)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## tokens from 2 documents.
## text1 :
## [1] &amp;quot;關關&amp;quot; &amp;quot;雎鳩&amp;quot; &amp;quot;、&amp;quot;   &amp;quot;在&amp;quot;   &amp;quot;河&amp;quot;   &amp;quot;之&amp;quot;   &amp;quot;洲&amp;quot;   &amp;quot;。&amp;quot;  
## 
## text2 :
## [1] &amp;quot;窈窕淑女&amp;quot; &amp;quot;、&amp;quot;       &amp;quot;君子&amp;quot;     &amp;quot;好逑&amp;quot;     &amp;quot;。&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This gives the same problem: 窈窕淑女 is one block.
But maybe with a dictionary this problem can be solved?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;quant.dict &amp;lt;- dictionary(list(ideo = c(&amp;quot;關關&amp;quot;, &amp;quot;窈窕&amp;quot;)))
quanteda.toks &amp;lt;- tokens(quanteda.corpus)
tokens_lookup(quanteda.toks, dictionary = quant.dict, levels = 1)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## tokens from 2 documents.
## text1 :
## [1] &amp;quot;ideo&amp;quot;
## 
## text2 :
## character(0)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dfm(quanteda.corpus, dictionary = quant.dict)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Document-feature matrix of: 2 documents, 1 feature (50.0% sparse).
## 2 x 1 sparse Matrix of class &amp;quot;dfm&amp;quot;
##        features
## docs    ideo
##   text1    1
##   text2    0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This isn&amp;rsquo;t really working &amp;ndash; the dictionary object in &lt;code&gt;quanteda&lt;/code&gt; is mostly something for further text analysis (after segmentation).
I do seem to remember there is a function that (&lt;a href=&#34;https://koheiw.net/?p=481&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;tokens_compound&lt;/code&gt;&lt;/a&gt;) that allows you to paste erroneously split words back together, but I don&amp;rsquo;t know if you can customize the cutting?&lt;/p&gt;

&lt;h2 id=&#34;jiebar&#34;&gt;&lt;code&gt;jiebaR&lt;/code&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cutter = worker()
segment(test, cutter)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;關關雎&amp;quot;   &amp;quot;鳩&amp;quot;       &amp;quot;在&amp;quot;       &amp;quot;河之洲&amp;quot;   &amp;quot;窈窕淑女&amp;quot; &amp;quot;君子好逑&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I wish I knew how to get the dictionary working, because then I would be able to just stay in R.
If anybody knows the fucntions, please tell me.
I would want something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;jiebaR.dict &amp;lt;- c(&amp;quot;關關 5 id&amp;quot;, &amp;quot;窈窕 5 id&amp;quot;)
cutter2 &amp;lt;- worker(dict = jiebaR.dict)
segment(test, cutter2)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;udpipe&#34;&gt;&lt;code&gt;udpipe&lt;/code&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#udmodel &amp;lt;- udpipe_download_model(language = &amp;quot;classical_chinese-kyoto&amp;quot;)
udmodel_KC &amp;lt;- udpipe_load_model(file = &amp;quot;classical_chinese-kyoto-ud-2.4-190531.udpipe&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;x &amp;lt;- udpipe_annotate(udmodel_KC, x = test)
x &amp;lt;- as.data.frame(x)

tibble(x$token, x$upos)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 18 x 2
##    `x$token` `x$upos`
##    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;   
##  1 關        NOUN    
##  2 關雎      NOUN    
##  3 鳩        VERB    
##  4 、        PUNCT   
##  5 在        VERB    
##  6 河        NOUN    
##  7 之        SCONJ   
##  8 洲        VERB    
##  9 。        PUNCT   
## 10 窈        VERB    
## 11 窕        VERB    
## 12 淑        VERB    
## 13 女        PRON    
## 14 、        PUNCT   
## 15 君子      NOUN    
## 16 好        VERB    
## 17 逑        VERB    
## 18 。        PUNCT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Wow this is really weird.
It splits 關關雎鳩 as &lt;code&gt;關 關雎 鳩&lt;/code&gt; instead of &lt;code&gt;關關 雎鳩&lt;/code&gt;, and 窈窕淑女 as &lt;code&gt;窈 窕 淑 女&lt;/code&gt; instead of the desired &lt;code&gt;窈窕 淑女&lt;/code&gt;.
I don&amp;rsquo;t think I know how to improve this currently, as there are some dictionary settings that allow you to &lt;em&gt;suggest&lt;/em&gt; but not necessarily &lt;em&gt;enforce&lt;/em&gt; it.
Once again, if you know how, tell me now.&lt;/p&gt;

&lt;h2 id=&#34;jieba-in-python&#34;&gt;&lt;code&gt;jieba&lt;/code&gt; in python&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import jieba
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;seg_list = jieba.cut(&amp;quot;關關雎鳩、在河之洲。&amp;quot;, cut_all=False)
print(&amp;quot;Default Mode: &amp;quot; + &amp;quot;/ &amp;quot;.join(seg_list))  # 默认模式
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Default Mode: 關關/ 雎/ 鳩/ 、/ 在/ 河之洲/ 。
## 
## --- Logging error ---
## Traceback (most recent call last):
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py&amp;quot;, line 985, in emit
##     stream.write(msg)
## ValueError: I/O operation on closed file
## Call stack:
##   File &amp;quot;&amp;lt;string&amp;gt;&amp;quot;, line 1, in &amp;lt;module&amp;gt;
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 301, in cut
##     for word in cut_block(blk):
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 233, in __cut_DAG
##     DAG = self.get_DAG(sentence)
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 179, in get_DAG
##     self.check_initialized()
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 168, in check_initialized
##     self.initialize()
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 111, in initialize
##     default_logger.debug(&amp;quot;Building prefix dict from %s ...&amp;quot; % (abs_path or &#39;the default dictionary&#39;))
## Message: &#39;Building prefix dict from the default dictionary ...&#39;
## Arguments: ()
## --- Logging error ---
## Traceback (most recent call last):
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py&amp;quot;, line 985, in emit
##     stream.write(msg)
## ValueError: I/O operation on closed file
## Call stack:
##   File &amp;quot;&amp;lt;string&amp;gt;&amp;quot;, line 1, in &amp;lt;module&amp;gt;
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 301, in cut
##     for word in cut_block(blk):
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 233, in __cut_DAG
##     DAG = self.get_DAG(sentence)
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 179, in get_DAG
##     self.check_initialized()
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 168, in check_initialized
##     self.initialize()
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 145, in initialize
##     &amp;quot;Dumping model to file cache %s&amp;quot; % cache_file)
## Message: &#39;Dumping model to file cache /var/folders/kn/bjb0w7nx061145pnsxtwzpgc0000gn/T/jieba.cache&#39;
## Arguments: ()
## --- Logging error ---
## Traceback (most recent call last):
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py&amp;quot;, line 985, in emit
##     stream.write(msg)
## ValueError: I/O operation on closed file
## Call stack:
##   File &amp;quot;&amp;lt;string&amp;gt;&amp;quot;, line 1, in &amp;lt;module&amp;gt;
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 301, in cut
##     for word in cut_block(blk):
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 233, in __cut_DAG
##     DAG = self.get_DAG(sentence)
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 179, in get_DAG
##     self.check_initialized()
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 168, in check_initialized
##     self.initialize()
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 163, in initialize
##     &amp;quot;Loading model cost %.3f seconds.&amp;quot; % (time.time() - t1))
## Message: &#39;Loading model cost 1.477 seconds.&#39;
## Arguments: ()
## --- Logging error ---
## Traceback (most recent call last):
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py&amp;quot;, line 985, in emit
##     stream.write(msg)
## ValueError: I/O operation on closed file
## Call stack:
##   File &amp;quot;&amp;lt;string&amp;gt;&amp;quot;, line 1, in &amp;lt;module&amp;gt;
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 301, in cut
##     for word in cut_block(blk):
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 233, in __cut_DAG
##     DAG = self.get_DAG(sentence)
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 179, in get_DAG
##     self.check_initialized()
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 168, in check_initialized
##     self.initialize()
##   File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/jieba/__init__.py&amp;quot;, line 164, in initialize
##     default_logger.debug(&amp;quot;Prefix dict has been built succesfully.&amp;quot;)
## Message: &#39;Prefix dict has been built succesfully.&#39;
## Arguments: ()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;seg_list = jieba.cut(&amp;quot;窈窕淑女、君子好逑。&amp;quot;, cut_all=False)
#print(&amp;quot;Default Mode: &amp;quot; + &amp;quot;/ &amp;quot;.join(seg_list))  # 默认模式
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This doesn&amp;rsquo;t give the desired results.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;a &amp;lt;-  c(&amp;quot;關關 5&amp;quot;, &amp;quot;窈窕 500&amp;quot;, &amp;quot;雎鳩&amp;quot;)
a
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;關關 5&amp;quot;   &amp;quot;窈窕 500&amp;quot; &amp;quot;雎鳩&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(r.a)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [&#39;關關 5&#39;, &#39;窈窕 500&#39;, &#39;雎鳩&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;jieba.load_userdict(r.a)
#add_word(&#39;雎鳩&#39;, freq=None, tag=None)

seg_list = jieba.cut(&amp;quot;關關雎鳩、在河之洲。&amp;quot;, cut_all=False)
print(&amp;quot;Default Mode: &amp;quot; + &amp;quot;/ &amp;quot;.join(seg_list))  # 默认模式
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Default Mode: 關關/ 雎鳩/ 、/ 在/ 河之洲/ 。
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;seg_list = jieba.cut(&amp;quot;窈窕淑女、君子好逑。&amp;quot;, cut_all=False)
print(&amp;quot;Default Mode: &amp;quot; + &amp;quot;/ &amp;quot;.join(seg_list))  # 默认模式
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Default Mode: 窈窕淑女/ 、/ 君子好逑/ 。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see, it is really easy to just define a dictionary in R, because it is just a list (instead of feeding it a .txt file).
But I still don&amp;rsquo;t know how to enforce it.
Do I just change the weight, and if so to what setting?&lt;/p&gt;

&lt;h2 id=&#34;ckiptagger-in-python&#34;&gt;&lt;code&gt;ckiptagger&lt;/code&gt; (in python)&lt;/h2&gt;

&lt;p&gt;Last on the list is the recent &lt;code&gt;ckiptagger&lt;/code&gt; library.
According to the &lt;a href=&#34;https://github.com/ckiplab/ckiptagger&#34; target=&#34;_blank&#34;&gt;github page&lt;/a&gt; this model outperforms &lt;code&gt;jieba&lt;/code&gt;:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Tool&lt;/th&gt;
&lt;th&gt;(WS) prec&lt;/th&gt;
&lt;th&gt;(WS) rec&lt;/th&gt;
&lt;th&gt;(WS) f1&lt;/th&gt;
&lt;th&gt;(POS) acc&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;CkipTagger&lt;/td&gt;
&lt;td&gt;97.49%&lt;/td&gt;
&lt;td&gt;97.17%&lt;/td&gt;
&lt;td&gt;97.33%&lt;/td&gt;
&lt;td&gt;94.59%&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;CKIPWS (classic)&lt;/td&gt;
&lt;td&gt;95.85%&lt;/td&gt;
&lt;td&gt;95.96%&lt;/td&gt;
&lt;td&gt;95.91%&lt;/td&gt;
&lt;td&gt;90.62%&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Jieba-zh_TW&lt;/td&gt;
&lt;td&gt;90.51%&lt;/td&gt;
&lt;td&gt;89.10%&lt;/td&gt;
&lt;td&gt;89.80%&lt;/td&gt;
&lt;td&gt;&amp;ndash;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;I recommend following the steps for installation outlined over there because their tagged set is quite large (1.8 GB I or so), so you want that downloaded directly to your harddrive or a virtual environment or whatever it is the young kids do these days.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from ckiptagger import *
#data_utils.download_data_gdown(&amp;quot;./&amp;quot;) # gdrive-ckip
#ws = WS(&amp;quot;./data&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_qint8 = np.dtype([(&amp;quot;qint8&amp;quot;, np.int8, 1)])
## /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_quint8 = np.dtype([(&amp;quot;quint8&amp;quot;, np.uint8, 1)])
## /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_qint16 = np.dtype([(&amp;quot;qint16&amp;quot;, np.int16, 1)])
## /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_quint16 = np.dtype([(&amp;quot;quint16&amp;quot;, np.uint16, 1)])
## /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_qint32 = np.dtype([(&amp;quot;qint32&amp;quot;, np.int32, 1)])
## /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   np_resource = np.dtype([(&amp;quot;resource&amp;quot;, np.ubyte, 1)])
## /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_qint8 = np.dtype([(&amp;quot;qint8&amp;quot;, np.int8, 1)])
## /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_quint8 = np.dtype([(&amp;quot;quint8&amp;quot;, np.uint8, 1)])
## /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_qint16 = np.dtype([(&amp;quot;qint16&amp;quot;, np.int16, 1)])
## /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_quint16 = np.dtype([(&amp;quot;quint16&amp;quot;, np.uint16, 1)])
## /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_qint32 = np.dtype([(&amp;quot;qint32&amp;quot;, np.int32, 1)])
## /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   np_resource = np.dtype([(&amp;quot;resource&amp;quot;, np.ubyte, 1)])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ws = WS(&amp;quot;/Users/Thomas/data&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;word_list = ws(
    r.test 
    )
    
word_list
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [[&#39;關關&#39;, &#39;雎鳩&#39;, &#39;、&#39;, &#39;在&#39;, &#39;河&#39;, &#39;之&#39;, &#39;洲&#39;, &#39;。&#39;], [&#39;窈窕淑女&#39;, &#39;、&#39;, &#39;君子&#39;, &#39;好逑&#39;, &#39;。&#39;]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is not ideal, but lets make a dictionary here too and run it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ideos &amp;lt;- c(&amp;quot;關關&amp;quot;, &amp;quot;窈窕&amp;quot;)
vals &amp;lt;- c(rep(5, times = 2))

lijst &amp;lt;- as.list(vals)
names(lijst) &amp;lt;- ideos

lijst
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $關關
## [1] 5
## 
## $窈窕
## [1] 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is the format you want, because it matches the python format of &amp;lsquo;dictionaries&amp;rsquo; the best.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;dictionario = construct_dictionary(r.lijst)
print(dictionario)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [(2, {&#39;關關&#39;: 5.0, &#39;窈窕&#39;: 5.0})]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;word_list = ws(
    r.test,
    coerce_dictionary = dictionario
    )
    
word_list
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [[&#39;關關&#39;, &#39;雎鳩&#39;, &#39;、&#39;, &#39;在&#39;, &#39;河&#39;, &#39;之&#39;, &#39;洲&#39;, &#39;。&#39;], [&#39;窈窕&#39;, &#39;淑女&#39;, &#39;、&#39;, &#39;君子&#39;, &#39;好逑&#39;, &#39;。&#39;]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By using the &lt;code&gt;coerce_dictionary&lt;/code&gt; argument, you &lt;em&gt;force&lt;/em&gt; this dictionary, to be used.
So theoretically it should look at that first before it throws other segmentation stuff at the data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;py$word_list %&amp;gt;%
  #unlist()%&amp;gt;%
  enframe() %&amp;gt;%
  unnest(value) %&amp;gt;%
  group_by(name) %&amp;gt;%
  summarise(sentence = str_c(value, collapse = &amp;quot; &amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 2
##    name sentence                   
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;                      
## 1     1 關關 雎鳩 、 在 河 之 洲 。
## 2     2 窈窕 淑女 、 君子 好逑 。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Et voilà, segmented Classical Chinese, the way I want it.
(Well, I guess I would want 好逑 to be split in 好 and 逑 as well, but for now it&amp;rsquo;s okay.)&lt;/p&gt;

&lt;p&gt;The steps in this section thus consist of:
1. Providing target text (character vectors in R)
2. Making the dictionary (list in R)
3. Transforming the R dictionary to python dictionary (dictionary in python)
4. Running python script (import ckiptagger, load the ws data, run ws function with dictionary coerced)
5. Transform python object to nice dataframe in R (dataframe in R)&lt;/p&gt;

&lt;p&gt;I can readily see applications with a dictionary list taken from the &lt;a href=&#34;https://osf.io/kpwgf/&#34; target=&#34;_blank&#34;&gt;Chinese Ideophone Database CHIDEOD&lt;/a&gt;, and maybe with other databases connected to it as well.&lt;/p&gt;

&lt;p&gt;But I&amp;rsquo;m always open to hearing more ways of dealing with this preprocessing problem.&lt;/p&gt;

&lt;h1 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h1&gt;

&lt;p&gt;Above I&amp;rsquo;ve showcased a number of packages and ways to deal with the problem of Chinese Word Segmentation.
Here&amp;rsquo;s the score I would give them.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;package / library&lt;/th&gt;
&lt;th&gt;coding language&lt;/th&gt;
&lt;th&gt;score&lt;/th&gt;
&lt;th&gt;comment&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;tidytext&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;R&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;if you want a quick solution (&amp;ldquo;characters&amp;rdquo;) or okayish solution (&amp;ldquo;words&amp;rdquo;)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;quanteda&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;R&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;okayish solution, can&amp;rsquo;t split smaller?&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;jiebaR&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;R&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;how to use the dictionary function?&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;udpipe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;R&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;not developed enough / unclear instructions&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;jieba&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;python&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;with dictionaries you can get there, maybe; but how to enforce them?&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ckiptgagger&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;R + python&lt;/td&gt;
&lt;td&gt;9.5&lt;/td&gt;
&lt;td&gt;this method seems to get the ideophone job done, dictionaries can be enforced, but might also not be perfect?&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;I hope you found this blog useful, but should you have tips on how to improve the workflow, always welcome.&lt;/strong&gt;
And thanks for sticking around until here.
As we say in Taiwan: 謝謝拜拜。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Guanguan goes the Chinese Word Segmentation (I)</title>
      <link>/post/guanguan-goes-the-chinese-word-segmentation/</link>
      <pubDate>Sun, 08 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/post/guanguan-goes-the-chinese-word-segmentation/</guid>
      <description>

&lt;h1 id=&#34;tl-dr&#34;&gt;tl; dr&lt;/h1&gt;

&lt;p&gt;This double blog is first about the opening line of the &lt;em&gt;Book of Odes&lt;/em&gt;, and later about how to deal with Chinese word segmentation, and my current implementation of it. So if you&amp;rsquo;re only &lt;a href=&#34;../guanguan-goes-the-chinese-word-segmentation-2&#34;&gt;interested in the computational part, look at the next one&lt;/a&gt;. If, on the other hand, you want to know more about my views on the translation of &lt;em&gt;guān guān&lt;/em&gt; etc., &lt;a href=&#34;../guanguan-goes-the-chinese-word-segmentation&#34;&gt;look at the first part&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;

&lt;p&gt;The other day I was browsing through some academic journals, and I came across this article by &lt;a href=&#34;https://en.wikipedia.org/wiki/Geoffrey_Sampson&#34; target=&#34;_blank&#34;&gt;Geoffrey Sampson&lt;/a&gt;, who I know mostly from (convincingly) attacking the Language Instinct hypothesis in linguistics.
That led me to his website ( &lt;a href=&#34;https://www.grsampson.net/REmpNat.html&#34; target=&#34;_blank&#34;&gt;see here for the Language Instinct thing&lt;/a&gt; ), where I then found out has written a book that translates 58 poems from the &lt;a href=&#34;https://en.wikipedia.org/wiki/Classic_of_Poetry&#34; target=&#34;_blank&#34;&gt;Shījīng&lt;/a&gt; 詩經, the &lt;em&gt;Book of Odes&lt;/em&gt; or &lt;em&gt;Book of Songs&lt;/em&gt; as it&amp;rsquo;s most commonly known in English.
Sampson uses Baxter&amp;rsquo;s (1992) reconstruction of Old Chinese on the left-hand side and translates poems on the right-hand side, &lt;a href=&#34;https://www.grsampson.net/BLoveSEC.html&#34; target=&#34;_blank&#34;&gt;see here&lt;/a&gt;.
This book was also reviewed by the &lt;a href=&#34;https://en.wikipedia.org/wiki/Edward_L._Shaughnessy&#34; target=&#34;_blank&#34;&gt;Edward Shaughnessy&lt;/a&gt;, an expert on very old Chinese (Shaughnessy, Edward. 2008. &lt;em&gt;Modern Philology&lt;/em&gt; (106). 197-2000), where he argued that it&amp;rsquo;s a nice translation, but then critiques some of the choices made.&lt;/p&gt;

&lt;h1 id=&#34;the-issue&#34;&gt;The issue&lt;/h1&gt;

&lt;p&gt;And this is where I address the topic of this blog post. The criticism is about the very first stanza of the very first ode of the &lt;em&gt;Shījīng&lt;/em&gt;, called &lt;em&gt;Guān jū&lt;/em&gt; 關雎.
I&amp;rsquo;ll first give this poem in full, with a translation by &lt;a href=&#34;https://en.wikipedia.org/wiki/James_Legge&#34; target=&#34;_blank&#34;&gt;James Legge&lt;/a&gt; (dating from 1871), based on the &lt;a href=&#34;https://ctext.org/book-of-poetry/guan-ju&#34; target=&#34;_blank&#34;&gt;ctext&lt;/a&gt; and the book (&lt;em&gt;The She King&lt;/em&gt;) iself.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;關關雎鳩、在河之洲。&lt;br /&gt;
窈窕淑女、君子好逑。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Kwan-kwan&lt;/em&gt; go the ospreys,&lt;br /&gt;
On the islet in the river.&lt;br /&gt;
The modest, retiring, virtuous, young lady: —&lt;br /&gt;
For our prince a good mate she.&lt;/p&gt;

&lt;p&gt;參差荇菜、左右流之。&lt;br /&gt;
窈窕淑女、寤寐求之。&lt;br /&gt;
求之不得、寤寐思服。&lt;br /&gt;
悠哉悠哉、輾轉反側。&lt;/p&gt;

&lt;p&gt;Here long, there short, is the duckweed,&lt;br /&gt;
To the left, to the right, borne about by the current.&lt;br /&gt;
The modest, retiring, virtuous, young lady: —&lt;br /&gt;
Waking and sleeping, he sought her.&lt;br /&gt;
He sought her and found her not,&lt;br /&gt;
And waking and sleeping he thought about her.&lt;br /&gt;
Long he thought; oh! long and anxiously;&lt;br /&gt;
On his side, on his back, he turned, and back again.&lt;/p&gt;

&lt;p&gt;參差荇菜、左右采之。&lt;br /&gt;
窈窕淑女、琴瑟友之。&lt;br /&gt;
參差荇菜、左右芼之。&lt;br /&gt;
窈窕淑女、鍾鼓樂之。&lt;/p&gt;

&lt;p&gt;Here long, there short, is the duckweed;&lt;br /&gt;
On the left, on the right, we gather it.&lt;br /&gt;
The modest, retiring, virtuous, young lady: —&lt;br /&gt;
With lutes, small and large, let us give her friendly welcome.&lt;br /&gt;
Here long, there short, is the duckweed;&lt;br /&gt;
On the left, on the right, we cook and present it.&lt;br /&gt;
The modest, retiring, virtuous, young lady: —&lt;br /&gt;
With bells and drums let us show our delight in her.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So as I said, Sampson&amp;rsquo;s (2006) version gives the first line as follows:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Krón, krón, tsa-kou&lt;br /&gt;
Dzúh gáy tu tou&lt;br /&gt;
Íwh-líwh diwk nrah&lt;br /&gt;
Koun-tzuh hóuh grou.&lt;/p&gt;

&lt;p&gt;Krón, krón calls the fish-hawk
on an islet in the river.&lt;br /&gt;
A girl who is lovely and good&lt;br /&gt;
Is the fit match for a princely man.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let&amp;rsquo;s first see how this compares to the other translations Shaughnessy discusses, for example &lt;a href=&#34;https://en.wikipedia.org/wiki/Arthur_Waley&#34; target=&#34;_blank&#34;&gt;Arthur Waley &lt;/a&gt; (1937 / 1987:81):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;lsquo;Fair, fair,&amp;rsquo; cry the ospreys&lt;br /&gt;
On the island in the river.&lt;br /&gt;
Lovely is this noble lady,&lt;br /&gt;
Fit bride for our lord.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Or &lt;a href=&#34;https://en.wikipedia.org/wiki/Bernhard_Karlgren&#34; target=&#34;_blank&#34;&gt;Bernhard Karlgren&lt;/a&gt; (1950:2):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Kwan-kwan&lt;/em&gt; (cries) the ts&amp;rsquo;ü-kiu bird, on the islet of the river;&lt;br /&gt;
the beautiful and good girl, she is a good mate for the lord.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As for the quality of translation, I agree with Shaughnessy that Sampson&amp;rsquo;s is not necessarily better than Legge, Waley or Karlgren.
My personal preference in this case still goes to the one by Legge (1871!).&lt;/p&gt;

&lt;h1 id=&#34;the-first-ideophone&#34;&gt;The first ideophone&lt;/h1&gt;

&lt;p&gt;But what is the most interesting, of course, is the SOUND ideophone (onomatopoeia) all the way in the beginning of the poem.
There seem to be a few choices possible: 1. either you keep the sound of the current Mandarin reading, i.e. &lt;em&gt;guānguān&lt;/em&gt; / &lt;em&gt;kwan-kwan&lt;/em&gt;; 2. or you translate with a possible English equivalent, i.e. &lt;em&gt;fair fair&lt;/em&gt;; 3. or you use the reconstructed pronunciation, to evoque what it might have sounded like (phonologically) in ancient times, i.e. &lt;em&gt;kron kron&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;So Shaughnessy at first seems to somewhat applaud the usage of &lt;em&gt;kron kron&lt;/em&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In principle, I believe that being able to &amp;ldquo;hear&amp;rdquo; the original is important to an appreciation of poetry, and so I think that the addition of these phonetic reconstructions is to be welcomed (although I am not at all sure that for readers who do not know Chinese &amp;ldquo;&lt;em&gt;Krón, krón, tsa-kou&lt;/em&gt;&amp;rdquo; Sampson’s reconstruction, is much to be preferred over &amp;ldquo;&lt;em&gt;Guan guan ju jiu&lt;/em&gt;&amp;rdquo; the standard Romanization of the modern Chinese pronunciation).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But later on he critiques this first line as well:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;&lt;em&gt;Krón, krón&lt;/em&gt;&amp;rdquo; is supposed to be onomatopoeia for the sound that the fish-hawk makes as he calls to his mate. But here as elsewhere in the &lt;em&gt;Shi jing&lt;/em&gt;, when animals, and especially birds, cry out, they do so in Chinese. In any event, their cries are necessarily rendered in Chinese characters, and the characters were obviously chosen not only for their sound but also for their meaning.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is followed by Shaughnessy inspecting Sampson&amp;rsquo;s glossary, where a singular &lt;em&gt;krón&lt;/em&gt; is glossed as a crossbeam in a gate, and then extended to include meanings as diverse as &amp;lsquo;pass (through mountains)&amp;rsquo;, &amp;lsquo;close&amp;rsquo;, &amp;lsquo;join, be related&amp;rsquo;.
And onomasiologically its form is similar to another word &lt;em&gt;guan&lt;/em&gt;, reconstructed as &lt;em&gt;kons&lt;/em&gt; &amp;lsquo;to pass through&amp;rsquo;, but extended to &amp;lsquo;penetrate&amp;rsquo; (yes in the sexual way).
So Shaughnessy argues that there is some penetrating punning going on:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It seems to me that the fish-hawk is literally seeking &amp;ldquo;join&amp;rdquo; with his mate, and any translation that does not reflect that sense leaves the reader at an immediate loss.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;While the rest of the review makes some good comments about the themes of lust (no caution) in the &lt;em&gt;Shījīng&lt;/em&gt;, this rubbed me a little in the wrong way.
But let&amp;rsquo;s now turn to Sampson&amp;rsquo;s &lt;a href=&#34;https://www.grsampson.net/CShau.html&#34; target=&#34;_blank&#34;&gt;reply&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The biggest point Sampson makes is that Chinese studies should do more popularizing their findings, and that can be said of many disciplines.
Books like his &lt;em&gt;Love songs in Early China&lt;/em&gt; do contribute to that goal.&lt;/p&gt;

&lt;p&gt;Then, about the first stanza where Shaughnessy critized Sampson&amp;rsquo;s &lt;em&gt;krón (krón)&lt;/em&gt; as involving a double entendre, Sampson dryly remarks: &amp;ldquo;Perhaps&amp;rdquo;.
And this is an apt response.&lt;/p&gt;

&lt;p&gt;It baffles me as well how you can relate onomatopoeia / SOUND ideophones, yes composed of characters, to just a reduplication of a homophone in this case.
As if translating 關關 with &amp;lsquo;beam-beam&amp;rsquo;, or &amp;lsquo;join-join&amp;rsquo; (Sampson), or &amp;lsquo;pass-pass&amp;rsquo; makes sense.
Shaughnessy&amp;rsquo;s point makes as much sense as in the hypothetical situation where we would have &lt;em&gt;boe, daar is de koe&lt;/em&gt; &amp;ldquo;moo, there is the cow&amp;rdquo; in Dutch with an English translation.
But &lt;em&gt;boe&lt;/em&gt; not only is the sound of a cow in Dutch, it is also what you use to scare someone, cf. English &lt;em&gt;boo&lt;/em&gt;.
So should that extension into the semantic domain of FEAR be brought into the translation?
Perhaps.
Or, second similar example: &lt;em&gt;tok tok tok — vier kippen op een rij&lt;/em&gt; &amp;ldquo;cluck cluck (cluck) — four chickens arranged in a row&amp;rdquo;.
Should we be translating &lt;em&gt;tok tok tok&lt;/em&gt; as &amp;lsquo;cluck&amp;rsquo;, or knowing full well that the sequence &lt;em&gt;tok tok tok&lt;/em&gt; is also used for &amp;lsquo;knocking sound (on a door)&amp;rsquo;, as &amp;ldquo;knock-knock go the four chickens&amp;rdquo;?
Perhaps not.&lt;/p&gt;

&lt;p&gt;These silly examples are just thrown in here to show that, as Sampson argues, it is &amp;ldquo;irrelevant&amp;rdquo; to go looking up his &lt;em&gt;krón&lt;/em&gt; when dealing with &lt;em&gt;krón krón&lt;/em&gt;.
The second retort is about the formally similar &lt;em&gt;kons&lt;/em&gt;.
Shaughnessy doesn&amp;rsquo;t give any characters (or tones) in his review, but this is what Sampson finds:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Having argued that 關, &lt;em&gt;krón&lt;/em&gt;, should be read partly for its sense, Shaughnessy then claims to discern yet another layer of meaning: he says that this word is “similar in pronunciation” to 貫, whose primary meaning is &amp;ldquo;to pass through&amp;rdquo; but which has &amp;ldquo;the extended sense of sexual penetration&amp;rdquo;. So perhaps the translation should be not &amp;ldquo; &amp;lsquo;Join, join&amp;rsquo; …&amp;rdquo; but rather &amp;ldquo; &amp;lsquo;Screw, screw&amp;rsquo; calls the fish-hawk&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;I find it surprising that the words 關 and 貫 were similar enough to be confusable in the Old Chinese period. (They are pronounced similarly in modern Mandarin – kuan1 [&lt;em&gt;guān&lt;/em&gt;] versus kuan4 [&lt;em&gt;guàn&lt;/em&gt;], a difference of tone only; but 貫 is normally taken to have ended in -&lt;em&gt;s&lt;/em&gt; in Old Chinese: Shaughnessy gives it the pronunciation &lt;em&gt;kons&lt;/em&gt;, and I would write &lt;em&gt;kóns&lt;/em&gt;.) &lt;strong&gt;However, in private correspondence Shaughnessy has shown me good evidence that the words were treated as to some extent interchangeable. Nevertheless, I remain sceptical about whether the meaning, rather than the pronunciation, of either word was relevant to hearers&amp;rsquo; appreciation of the poem. Rendering a crowing sound into human speech by using a word pronounced &lt;em&gt;krón&lt;/em&gt; seems very natural.&lt;/strong&gt; Translating the first word of the Book of Odes into English with a term referring to sexual penetration would not only read bizarrely but be philologically gratuitous. (It might have helped with sales, perhaps.)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This also piqued my interest.
While it may be true that these words were somewhat interchangeable, in single syllables, it is still a bit harder to argue that the same goes for the reduplicated form, especially if we&amp;rsquo;re dealing with SOUND ideophones, who usually display IMAGIC ICONICITY (cf. all the literature on ideophones ever in the last ten years or so, but also e.g. Dingemanse 2012; Thompson 2019).&lt;/p&gt;

&lt;p&gt;But let&amp;rsquo;s follow the argument okay, and compare with some advances in the reconstruction of Old Chinese phonology.
The table below shows the Mandarin, Middle Chinese (Baxter 1992) and Old Chinese (Baxter &amp;amp; Sagart 2014; B&amp;amp;S) as &lt;a href=&#34;http://ocbaxtersagart.lsait.lsa.umich.edu&#34; target=&#34;_blank&#34;&gt;it is found on their website&lt;/a&gt;, unless otherwise indicated.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;character&lt;/th&gt;
&lt;th&gt;Mandarin&lt;/th&gt;
&lt;th&gt;Middle Chinese&lt;/th&gt;
&lt;th&gt;Old Chinese&lt;/th&gt;
&lt;th&gt;source&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;關(关)&lt;/td&gt;
&lt;td&gt;guān&lt;/td&gt;
&lt;td&gt;kwaen&lt;/td&gt;
&lt;td&gt;[k]ˤro[n]&lt;/td&gt;
&lt;td&gt;B&amp;amp;S (2014)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;關&lt;/td&gt;
&lt;td&gt;kwan1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;krón&lt;/td&gt;
&lt;td&gt;Sampson (2006; 2009)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;guan&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;kron&lt;/td&gt;
&lt;td&gt;Shaughnessy (2008)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;guan&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;kons&lt;/td&gt;
&lt;td&gt;Shaughnessy (2008)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;貫&lt;/td&gt;
&lt;td&gt;kwan4&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;kóns&lt;/td&gt;
&lt;td&gt;Sampson (2009)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;貫&lt;/td&gt;
&lt;td&gt;guàn&lt;/td&gt;
&lt;td&gt;kwan&lt;/td&gt;
&lt;td&gt;[k]ˤo[n]-s&lt;/td&gt;
&lt;td&gt;B&amp;amp;S (2014)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;管&lt;/td&gt;
&lt;td&gt;guǎn&lt;/td&gt;
&lt;td&gt;kwanX&lt;/td&gt;
&lt;td&gt;[k]ˤo[n]ʔ&lt;/td&gt;
&lt;td&gt;B&amp;amp;S (2014)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;口管&lt;/td&gt;
&lt;td&gt;guān (?)&lt;/td&gt;
&lt;td&gt;kwan (?)&lt;/td&gt;
&lt;td&gt;[k]ˤo[n] (?)&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;I tried ordering them according to the train of thought in this debate:
so first you have the current B&amp;amp;S transcription, basically &lt;em&gt;kˤron&lt;/em&gt;, then Sampson&amp;rsquo;s &lt;em&gt;krón&lt;/em&gt;, followed by Shaughnessy&amp;rsquo;s &lt;em&gt;krón&lt;/em&gt; and possible formal variant &lt;em&gt;kons&lt;/em&gt;, followed by Sampson&amp;rsquo;s answer that that would be &lt;em&gt;kóns&lt;/em&gt; in his system.
Next I give the B&amp;amp;S version of that &lt;em&gt;kons/kóns&lt;/em&gt;, and the last two are suggestions I found in Legge (1871): that 關 is sometimes read as 管 or MOUTH(口)-管, &amp;lsquo;flute&amp;rsquo;.
Personally, those last ones seem the most convincing for alternative characters of 關關: 管管 or (口管口管) &amp;lsquo;flute flute&amp;rsquo;, as in a sharp sound or so.&lt;/p&gt;

&lt;p&gt;Now what does the biggest dictionary of Chinese I have access to say about 關關?
The &lt;em&gt;Hànyǔ dà cídiǎn&lt;/em&gt; 漢語大詞典 says:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;1.鳥類雌雄相和的鳴聲。 後亦泛指鳥鳴聲。&lt;br /&gt;
Mating call of male and female birds.&lt;br /&gt;
《詩‧周南‧關雎》： “關關雎鳩， 在河之洲。”&lt;br /&gt;
  毛 傳： “關關， 和聲也。”&lt;br /&gt;
  南朝 宋 鮑照 《代悲哉行》： “翩翩翔禽羅， 關關鳴鳥列。”&lt;br /&gt;
  清 陸以湉 《冷廬雜識‧道情》： “只聽得流水潺潺， 鳥語關關。”&lt;br /&gt;
2.和諧安適貌。&lt;br /&gt;
Harmonious.&lt;br /&gt;
唐 錢起 《暇日覽舊詩因以題詠》： “逍遙心地得關關， 偶被功名涴我閒。”&lt;br /&gt;
3.車行聲。&lt;br /&gt;
Sound of carts passing.&lt;br /&gt;
明 何景明 《憶昔行》： “明星迢迢車關關， 遙向 楚 水辭 燕 山。”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So, no &amp;lsquo;beams&amp;rsquo; in sight &amp;ndash; maybe with some stretching you could argue for &amp;lsquo;passing through (of carts)&amp;rsquo; and then that sound, but still mostly just the call of these mysterious birds.
Yes, you read that correctly, we don&amp;rsquo;t actually really know what the bird is (or maybe now we do?, baidu and wikipedia do lead me to pictures), but the most common translation of &lt;em&gt;jūjiū&lt;/em&gt; &amp;lt; tshjo kjuw &amp;lt; [tsʱ]a [k](r)u 雎鳩 is &amp;lsquo;osprey&amp;rsquo; or &amp;lsquo;fish-hawk&amp;rsquo;.
Perhaps they are indeed a symbol of sex, because they eat fish, and fish are sexual symbols (Shaughnessy 2008).
Sampson (2009) notes that he just chose &amp;lsquo;fish-hawk&amp;rsquo; because the osprey (apparently &lt;em&gt;Pandion haliaetus&lt;/em&gt;) makes a very shrill sound, not very love-inspiring.
Perhaps this was also a case of the literature critic &amp;ndash; Shaugnessy &amp;ndash; reading too much into a pragmatic translation choice.&lt;/p&gt;

&lt;p&gt;So for me in general, it seems Sampson is the winner in this debate, it&amp;rsquo;s better to use &lt;em&gt;krón krón&lt;/em&gt; (or maybe now &lt;em&gt;kˤron kˤron&lt;/em&gt; if you want to be a Peter precise) than Mandarin &lt;em&gt;guānguān&lt;/em&gt; or whatever translationese.&lt;/p&gt;

&lt;p&gt;But he&amp;rsquo;s not entirely without faults either.
A grave example is when Shaughnessy discusses the merits of using the reconstructed Old Chinese (cf. above):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;[&amp;hellip;] (although I am not at all sure that for readers who do not know Chinese &amp;ldquo;&lt;em&gt;Krón, krón, tsa-kou&lt;/em&gt;&amp;rdquo; Sampson’s reconstruction, is much to be preferred over &amp;ldquo;&lt;em&gt;Guan guan ju jiu&lt;/em&gt;&amp;rdquo; the standard Romanization of the modern Chinese pronunciation).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To which Sampson responds:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If the line were considered in isolation like that, there would be little or no reason to prefer one pronunciation over the other; it takes two to tango, and &lt;strong&gt;it certainly takes two lines of poetry to rhyme&lt;/strong&gt;. But the fact that the Book of Odes represents the first known use of rhyme anywhere in world literature is one of the fascinating things about it. So it would not be much use to an English-speaking reader to spell out the poems in a modern version of Chinese, in which the rhymes have been destroyed by three millennia of sound-change. &lt;strong&gt;(In Old Chinese, tsa-kou, fish-hawk, in the first line rhymed with tou, islet, in the second line, but in modern Mandarin chü-chiu scarcely rhymes with chou.&lt;/strong&gt; In other cases the original rhymes, assonances, and so forth have been even more thoroughly wrecked in the modern language.)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I&amp;rsquo;ve highlighted two parts: Sampson is right of course, the &lt;em&gt;Shījīng&lt;/em&gt; is one of the prime examples of rhyme and has actually been super useful in reconstruction Old Chinese, see for instance this exciting research by List (&lt;a href=&#34;https://link.springer.com/article/10.1186%2Fs40655-017-0021-8&#34; target=&#34;_blank&#34;&gt;2017&lt;/a&gt;; &lt;a href=&#34;https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_3149513&#34; target=&#34;_blank&#34;&gt;2019&lt;/a&gt;).
On the other hand, he remarks that &amp;ldquo;chü-chiu scarcely rhymes with chou&amp;rdquo;, which is a very strange remark to make, as &lt;em&gt;jūjiū&lt;/em&gt; [tɕy˥ tɕjoʊ˥] of course rhymes with &lt;em&gt;zhōu&lt;/em&gt; [ʈʂoʊ˥], there is not a hint of &lt;em&gt;scarcely&lt;/em&gt; in sight.&lt;/p&gt;

&lt;h1 id=&#34;the-other-ideophone&#34;&gt;The other ideophone&lt;/h1&gt;

&lt;p&gt;You thought this was &lt;em&gt;soro soro&lt;/em&gt; (Jap. ソロソロ &amp;lsquo;any time now&amp;rsquo;) winding down, but no, not yet.&lt;/p&gt;

&lt;p&gt;I want to draw attention to the second line of the first stanza as well, and compare again the different translations.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Line&lt;/th&gt;
&lt;th&gt;Translator&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;窈窕淑女&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;em&gt;yáotiáo shūnǚ&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;The &lt;strong&gt;modest, retiring, virtuous&lt;/strong&gt;, young lady: —&lt;/td&gt;
&lt;td&gt;Legge (1871)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Lovely&lt;/strong&gt; is this noble lady,&lt;/td&gt;
&lt;td&gt;Waley (1937)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;the &lt;strong&gt;beautiful and good&lt;/strong&gt; girl,&lt;/td&gt;
&lt;td&gt;Karlgren (1950)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;A girl who is &lt;strong&gt;lovely and good&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Sampson (2006)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;君子好逑&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;em&gt;jūnzi hǎo qiú&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;For our prince a good mate she.&lt;/td&gt;
&lt;td&gt;Legge (1871)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Fit bride for our lord.&lt;/td&gt;
&lt;td&gt;Waley (1937)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;she is a good mate for the lord.&lt;/td&gt;
&lt;td&gt;Karlgren (1950)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Is the fit match for a princely man.&lt;/td&gt;
&lt;td&gt;Sampson (2006)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Of course, I argue that this &lt;em&gt;yáotiáo&lt;/em&gt; 窈窕 is also an ideophone, more precisely one that expresses EVALUATION based on VISION:
the lady (&lt;em&gt;shūnǚ&lt;/em&gt; 淑女) is evaluated as lovely, beautiful, good, befitting the lord or gentlemen (&lt;em&gt;jūnzi&lt;/em&gt; 君子).
Or, as it&amp;rsquo;s found in the Chinese Ideophone Database &lt;a href=&#34;https://simazhi.shinyapps.io/Chineseideophone/&#34; target=&#34;_blank&#34;&gt;CHIDEOD&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;of women, coy and comely, reticent and withdrawn, winsome but withdrawn, delicate and demure; but some indication that the term can instead imply seductive sensuality; covert depths, hidden recesses; quiet(ly) and private(ly)
(Kroll 2015)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;Yáotiáo&lt;/em&gt; thus conforms to the crosslinguistic concept of an ideophone: it is marked (partial reduplication), a word (&amp;ldquo;listable in a lexicon&amp;rdquo;), that depicts (&amp;ldquo;not just describes&amp;rdquo;) a sensory image (&amp;ldquo;beautiful, lovely woman&amp;rdquo;) and belongs to an open lexical class, cf. Dingemanse (2012; 2019).&lt;/p&gt;

&lt;p&gt;But do the translations above also conform what this ideophone depicts? Without taking into account factors like adhering to a metrical scheme (eight syllables or something similar), my preference without doubt goes to Legge&amp;rsquo;s translation, because he captures the antithetical forces of &amp;ldquo;wanting to depict but being only able to describe&amp;rdquo; the best:
English doesn&amp;rsquo;t have any ideophones (as far as I&amp;rsquo;m aware) to depict the kind of women that befits this lord.&lt;/p&gt;

&lt;p&gt;But perhaps you won&amp;rsquo;t agree.
Let me know.&lt;/p&gt;

&lt;h1 id=&#34;the-end&#34;&gt;The end?&lt;/h1&gt;

&lt;p&gt;Anyway, let me just end with the best mix-and-match of this stanza, or how I would do it, given a somewhat academic audience and enough space, i.e. here on my blog.&lt;/p&gt;

&lt;p&gt;First I would give Baxter &amp;amp; Sagart&amp;rsquo;s reconstruction:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;[k]ˤro[n] [k]ˤro[n] [tsʱ]a [k](r)u&lt;br /&gt;
[dz]ˤəʕ [C.g]ˤaj tə tu&lt;br /&gt;
ʔˤ[e]wʔ lˤ[e]wʔ s-tiwk nraʔ&lt;br /&gt;
C.qur tsəʔ qʱˤuʔ g&amp;reg;u&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Then I would give the Middle Chinese reconstruction, instead of Baxter (1992), I would opt for the IPA version (I converted with &lt;a href=&#34;https://pypi.org/project/sinopy/&#34; target=&#34;_blank&#34;&gt;Sinopy&lt;/a&gt;):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;kwæn kwæn ʦʰjo kjuw¹&lt;br /&gt;
ʣoj² ɣa ʨi ʨuw¹&lt;br /&gt;
ʔew² dew² ɕuwk ɳjo³&lt;br /&gt;
kjun ʦi² xaw³ gjuw¹&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Last I would provide the Mandarin pronunciation:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;guānguān jūjiū&lt;br /&gt;
zài hé zhī zhōu&lt;br /&gt;
yǎotiǎo shūnǚ&lt;br /&gt;
jūnzi hǎo qiú&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This way you can kind of see how sounds change, as well as the way people perceive the &amp;ldquo;sounds of the &lt;em&gt;Shījīng&lt;/em&gt;.
Of course, we would need characters as well:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;關關雎鳩，&lt;br /&gt;
在河之洲。&lt;br /&gt;
窈窕淑女，&lt;br /&gt;
君子好逑。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And I would end with a translation:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Krōn, krōn&lt;/em&gt; the físh-hawks cáll,&lt;br /&gt;
ón the íslet ín the ríver.&lt;br /&gt;
délicáte, demúre, young lády,&lt;br /&gt;
fór the lórd a góód mate shé.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Of course I borrowed from previous translations, but I also tried to mark the prosody so there&amp;rsquo;s four stressed syllables in the metre of each line.
This, I think, is a more effective way of trying to marry the original four beat Chinese to English (where pentameter is the most frequent verse form).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Didn&amp;rsquo;t like the translation?&lt;/strong&gt;
&lt;strong&gt;Make me a better one!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I hope to see you back for the next update where we attack the problem of this verse and Chinese word segmentation.&lt;/p&gt;

&lt;p&gt;P.s. I have been quite lazy with my references, but if you want a specific reference, feel free to ask.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
